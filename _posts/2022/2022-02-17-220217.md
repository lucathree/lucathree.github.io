---
title: "220217_TIL - 딥러닝 복습"
layout: single
author_profile: true
read_time: true
related: true
categories:
- TIL
tags:
- Diary
- TodayILearned
toc: true
toc_sticky: true
---

"밑바닥부터 시작하는 딥러닝" 책을 바탕으로 딥러닝 기초 이론 복습 진행.

## 주요 학습 키워드

- 퍼셉트론
  - 가중치, 임계값, 편향
  - 단층 퍼셉트론 / 다층 퍼셉트론의 차이
  - 선형 vs. 비선형
- 신경망 
  - 출력층, 은닉층, 입력층
  - 다차원 배열 계산법
- 활성화 함수
  - 계단 함수, 시그모이드 함수, ReLU 함수, 항등 함수, 소프트맥스 함수
- 신경망 학습법
  - 손실 함수
    - 오차제곱합, 교차 엔트로피 오차
  - 배치
  - 경사하강법
    - 학습률 (learning rate)
    - 확률적 경사 하강법 (SGD)
  - 학습절차 : 미니배치 → 기울기 산출 → 매개변수 갱신 → 반복
- 오차역전파법
  - 국소적계산, 연쇄법칙, 합성 함수
  - 순전파 ↔ 역전파
  - Affine 계층, Softmax 계층, Softmax-with-Loss 계층
  - 기울기 확인 (Gradient Check)
- 최적화
  - 매개변수 갱신
    - SGD, 모멘텀, AdaGrad, Adam
  - 가중치 초깃값 설정
    - 기울기 소실
    - Xavier 초깃값
    - He 초깃값
  - 배치 정규화
  - 오버피팅 방지
    - 가중치 감소
    - 드롭아웃
  - 하이퍼파라미터 튜닝
- 합성곱신경망(CNN)
  - 합성곱 계층, 풀링 계층
    - 합성곱 연산 : 필터(커널), 패딩, 스트라이드
    - 3,4차원 데이터의 연산, im2col
  - LeNet, AlexNet
- 심층 신경망(=딥러닝)
  - 층을 깊게하는 것의 중요성
    - 매개변수의 수의 제한, 수용영역
  - VGG, GoogLeNet, ResNet
  - 강화학습

----

교육과정을 수료한지도 시간이 꽤 지났고, 아무래도 연습용 프로젝트를 새로 진행해봐야 할 것 같은데 한동안 손을 놓고 있었더니 감이 많이 떨어진 것 같아 다시 기초 이론부터 복습을 진행했다.

다행히 한번 공부했던 내용이라고 책 한권을 전부 읽는데 그리 긴 시간이 소요되지 않았고, 읽으면서 바로바로 다시 핵심적인 내용들이 떠올랐다. 복습 덕분에 처음에는 이해하지 못했거나 놓쳤던 개념들도 이번에 다시한번 확실하게 짚을 수 있었던 것 같아 유의미했다.
